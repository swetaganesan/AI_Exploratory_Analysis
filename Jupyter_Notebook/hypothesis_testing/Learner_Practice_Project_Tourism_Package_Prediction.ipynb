{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALuXcDjNDIHY"
      },
      "source": [
        "# **Practice Project - Classification and Hypothesis Testing: Travel Package Purchase Prediction**\n",
        "\n",
        "---------------\n",
        "\n",
        "## **Problem Statement**\n",
        "\n",
        "### **Context**\n",
        "\n",
        "You are a Data Scientist for a tourism company named \"Visit with us\". The Policy Maker of the company wants to enable and establish a viable business model to expand the customer base. A viable business model is a central concept that helps you to understand the existing ways of doing the business and how to change the ways for the benefit of the tourism sector.\n",
        "\n",
        "One of the ways to expand the customer base is to introduce a new offering of packages. Currently, there are 5 types of packages the company is offering - Basic, Standard, Deluxe, Super Deluxe, King. Looking at the data of the last year, we observed that 18% of the customers purchased the packages. However, it was difficult to identify the potential customers because customers were contacted at random without looking at the available information. \n",
        "\n",
        "The company is now planning to launch a new product i.e. Wellness Tourism Package. Wellness Tourism is defined as Travel that allows the traveler to maintain, enhance or kick-start a healthy lifestyle, and support or increase one's sense of well-being. This time company wants to harness the available data of existing and potential customers to target the right customers. \n",
        "\n",
        "You as a Data Scientist at \"**Visit with us**\" travel company has to analyze the customers' data and information to provide recommendations to the Policy Maker and build a model to predict the potential customer who is going to purchase the newly introduced travel package. The model will be built to make predictions before a customer is contacted.\n",
        " \n",
        "\n",
        "### **Objective**\n",
        "\n",
        "To build a model to predict which customer is potentially going to purchase the newly introduced travel package.\n",
        "\n",
        "\n",
        "### **Data Description**\n",
        "\n",
        "- CustomerID: Unique customer ID\n",
        "- ProdTaken: Whether the customer has purchased a package or not (0: No, 1: Yes)\n",
        "- Age: Age of customer\n",
        "- TypeofContact: How customer was contacted (Company Invited or Self Inquiry)\n",
        "- CityTier: City tier depends on the development of a city, population, facilities, and living standards. The categories are ordered i.e. Tier 1 > Tier 2 > Tier 3. It's the city the customer lives in. \n",
        "- DurationOfPitch: Duration of the pitch by a salesperson to the customer\n",
        "- Occupation: Occupation of customer\n",
        "- Gender: Gender of customer\n",
        "- NumberOfPersonVisiting: Total number of persons planning to take the trip with the customer\n",
        "- NumberOfFollowups: Total number of follow-ups has been done by the salesperson after the sales pitch\n",
        "- ProductPitched: Product pitched by the salesperson\n",
        "- PreferredPropertyStar: Preferred hotel property rating by customer\n",
        "- MaritalStatus: Marital status of customer\n",
        "- NumberOfTrips: Average number of trips in a year by customer\n",
        "- Passport: The customer has a passport or not (0: No, 1: Yes)\n",
        "- PitchSatisfactionScore: Sales pitch satisfaction score\n",
        "- OwnCar: Whether the customers own a car or not (0: No, 1: Yes)\n",
        "- NumberOfChildrenVisiting: Total number of children with age less than 5 planning to take the trip with the customer\n",
        "- Designation: Designation of the customer in the current organization\n",
        "- MonthlyIncome: Gross monthly income of the customer\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E4YZBS-DIHf"
      },
      "source": [
        "## **Importing the libraries required**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMQzlKJ6DIHf"
      },
      "outputs": [],
      "source": [
        "# Importing the basic libraries we will require for the project\n",
        "\n",
        "# Libraries to help with reading and manipulating data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Libaries to help with data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "# Importing the Machine Learning models we require from Scikit-Learn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Importing the other functions we may require from Scikit-Learn\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# To get diferent metric scores\n",
        "from sklearn.metrics import confusion_matrix,classification_report,roc_auc_score,precision_recall_curve,roc_curve,make_scorer\n",
        "\n",
        "# Code to ignore warnings from function usage\n",
        "import warnings;\n",
        "import numpy as np\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T70hdjZ0DIHg"
      },
      "source": [
        "## **Loading the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvdl3_cRDIHg"
      },
      "outputs": [],
      "source": [
        "# Loading the dataset - sheet_name parameter is used if there are Basicple tabs in the excel file.\n",
        "data=pd.read_excel(\"Tourism.xlsx\",sheet_name='Tourism')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0MHeGS4i8ih"
      },
      "source": [
        "## **Overview of the dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPg_OY5ZjFht"
      },
      "source": [
        "### **View the first and last 5 rows of the dataset**\n",
        "\n",
        "Let's **view the first few rows and last few rows** of the dataset in order to understand its structure a little better.\n",
        "\n",
        "We will use the head() and tail() methods from Pandas to do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIk0vT-eDIHh"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykWCYmkCjjSL"
      },
      "outputs": [],
      "source": [
        "data.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGYq7egVY1aH"
      },
      "source": [
        "### **Understand the shape of the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBIzuBoHYyhQ"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8L7PkirZCcI"
      },
      "source": [
        "* The dataset has 4888 rows and 20 columns. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ7gLdvCyt_y"
      },
      "source": [
        "### **Check the data types of the columns for the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgoAKuuODIHi"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRx2lSN6DIHj"
      },
      "source": [
        "- We can see that 8 columns have less than 4,888 non-null values i.e. columns have missing values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFxplf91DIHk"
      },
      "source": [
        "### **Check the percentage of missing values in each column**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vyc2HNS2DIHk"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(data={'% of Missing Values':round(data.isna().sum()/data.isna().count()*100,2)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4grtL-viDIHk"
      },
      "source": [
        "- The `Age` column has 4.62% missing values out of the total observations.\n",
        "- `TypeofContact` column has 0.51% missing values out of the total observations.\n",
        "- `DurationOfPitch` column has 5.14% missing values out of the total observations.\n",
        "- The `NumberOfFollowups` column has 0.92% missing values out of the total observations.\n",
        "- `PreferredPropertyStar` column has 0.53% missing values out of the total observations.\n",
        "- `NumberOfTrips` column has 2.86% missing values out of the total observations.\n",
        "- `NumberOfChildrenVisiting` column has 1.35% missing values out of the total observations.\n",
        "- The `MonthlyIncome` column has 4.77% missing values out of the total observations.\n",
        "- We will impute these values after we split the data into train and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IQYlO1nDIHl"
      },
      "source": [
        "### **Check the number of unique values in each column**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdzbzZJyDIHl"
      },
      "outputs": [],
      "source": [
        "data.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSoaneEcDIHm"
      },
      "source": [
        "- We can drop the column - CustomerID as it is unique for each customer and will not add value to the model.\n",
        "- Most of the variables are categorical except - Age, duration of pitch, monthly income, and number of trips of customers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64HNNKS6zEql"
      },
      "source": [
        "**Dropping the unique values column**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5aUdkFyDIHm"
      },
      "outputs": [],
      "source": [
        "# Dropping CustomerID column\n",
        "data.drop(columns='CustomerID',inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmFFlVjEDIHm"
      },
      "source": [
        "### **Question 1: Check the summary statistics of the dataset and write your observations (2 Marks)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPlb2R2XZkeW"
      },
      "source": [
        "**Let's check the statistical summary of the data.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mvc7uuGUDIHm"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "data.____________ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLuHL0pMDIHn"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SveeM6EADIHn"
      },
      "source": [
        "### **Check the count of each unique category in each of the categorical variables.** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkXk32VHDIHn"
      },
      "outputs": [],
      "source": [
        "# Making a list of all catrgorical variables \n",
        "cat_col=['TypeofContact', 'CityTier','Occupation', 'Gender', 'NumberOfPersonVisiting',\n",
        "       'NumberOfFollowups', 'ProductPitched', 'PreferredPropertyStar',\n",
        "       'MaritalStatus', 'Passport', 'PitchSatisfactionScore',\n",
        "       'OwnCar', 'NumberOfChildrenVisiting', 'Designation']\n",
        "\n",
        "# Printing number of count of each unique value in each column\n",
        "for column in cat_col:\n",
        "    print(data[column].value_counts())\n",
        "    print('-'*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0bUlGnXDIHn"
      },
      "source": [
        "- The Free lancer category in the occupation column has just 2 entries out of 4,888 observations.\n",
        "- We can see that Gender has 3 unique values which include - 'Fe Male' and 'Female'. This must be a data input error, we should replace 'Fe Male' with 'Female'.\n",
        "- NumberOfPersonVisiting equal to 5 has a count equal to 3 only.\n",
        "- The majority of the customers are married.\n",
        "- The majority of the customers own a car."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74Pr3GIVDIHo"
      },
      "outputs": [],
      "source": [
        "# Replacing 'Fe Male' with 'Female'\n",
        "data.Gender=data.Gender.replace('Fe Male', 'Female')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MNce7BqhiSK"
      },
      "outputs": [],
      "source": [
        "# Converting the data type of each categorical variable to 'category'\n",
        "for column in cat_col:\n",
        "    data[column]=data[column].astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsGcbpckhiSK"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DygdzBtVhiSK"
      },
      "outputs": [],
      "source": [
        "df = data.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "realistic-mortgage"
      },
      "source": [
        "## **Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arbitrary-intelligence"
      },
      "source": [
        "### **Question 2: Univariate Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mieBnCRTbgT-"
      },
      "source": [
        "Let's explore these variables in some more depth by observing their distributions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X76cVRmTb-Wb"
      },
      "source": [
        "We will first define a **hist_box() function** that provides both a boxplot and a histogram in the same visual, with which we can perform univariate analysis on the columns of this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkCMIPwlDIHp"
      },
      "outputs": [],
      "source": [
        "# Defining the hist_box() function\n",
        "def hist_box(data, col):\n",
        "    f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={'height_ratios': (0.15, 0.85)}, figsize=(12, 6))\n",
        "    # Adding a graph in each part\n",
        "    sns.boxplot(data=data, x=col, ax=ax_box, showmeans=True)\n",
        "    sns.histplot(data=data, x=col, kde=True, ax=ax_hist)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWt_lt0FguoH"
      },
      "source": [
        "#### **Question 2.1:  Plot the histogram and box plot for the variable `Age` using the hist_box function provided and write your insights. (1 Mark)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "215y0eRJgss3"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "hist_box(__________) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv5ySpzuhGdI"
      },
      "source": [
        "**Write your answers here:_____**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UklkmdoEWPD-"
      },
      "source": [
        "#### **Question 2.2:  Plot the histogram and box plot for the variable `Duration of Pitch` using the hist_box function provided and write your insights. (1 Mark)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztAq-TJigsvX"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "hist_box(________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryse_hoNhks6"
      },
      "source": [
        "**Write your answers here:_____**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btVJ9v70hpC0"
      },
      "outputs": [],
      "source": [
        "df[df['DurationOfPitch']>40]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBqq9cn5gIkB"
      },
      "source": [
        "- We can see that there are just two observations which can be considered as outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFiYQ3X5h1Ws"
      },
      "source": [
        "**Lets plot the histogram and box plot for the variable `Monthly Income` using the hist_box function**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gKihm03iHmg"
      },
      "outputs": [],
      "source": [
        "hist_box(df, 'MonthlyIncome')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmwwatTkiL5V"
      },
      "source": [
        "- The distribution for monthly income shows that most of the values lie between 20,000 to 40,000.\n",
        "- Income is one of the important factors to consider while approaching a customer with a certain package. We can explore this further in bivariate analysis. \n",
        "- There are some observations on the left and some observations on the right of the boxplot which can be considered as outliers. Let's check how many such extreme values are there. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgzGMDGGiNgV"
      },
      "outputs": [],
      "source": [
        "df[(df.MonthlyIncome>40000) | (df.MonthlyIncome<12000)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1895UhBCgIkC"
      },
      "source": [
        "- There are just four such observations which can be considered as outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAVSChdbiebm"
      },
      "source": [
        "**Lets plot the histogram and box plot for the variable `Number of Trips` using the hist_box function**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLzxgqSzip6d"
      },
      "outputs": [],
      "source": [
        "hist_box(df,'NumberOfTrips')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUNEYCZHgIkC"
      },
      "source": [
        "- The distribution for the number of trips is right-skewed \n",
        "- Boxplot shows that the number of trips has some outliers at the right end. Let's check how many such extreme values are there. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqNarN63gIkD"
      },
      "outputs": [],
      "source": [
        "df.NumberOfTrips.value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaw2vYzagIkD"
      },
      "source": [
        "- We can see that most of the customers i.e. 52% have taken 2 or 3 trips.\n",
        "- As expected, with the increase in the number of trips the percentage of customers is decreasing.\n",
        "- The percentage of categories 19 or above is very less. We can consider these values as outliers.\n",
        "- We can see that there are just four observations with a number of trips 19 or greater"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2nYGPa7gIkD"
      },
      "source": [
        "**Removing these outliers form duration of pitch, monthly income, and number of trips.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwOOx9KYgIkD"
      },
      "outputs": [],
      "source": [
        "# Dropping observaions with duration of pitch greater than 40. There are just 2 such observations\n",
        "df.drop(index=df[df.DurationOfPitch>37].index,inplace=True)\n",
        "\n",
        "# Dropping observation with monthly income less than 12000 or greater than 40000. There are just 4 such observations\n",
        "df.drop(index=df[(df.MonthlyIncome>40000) | (df.MonthlyIncome<12000)].index,inplace=True)\n",
        "\n",
        "# Dropping observations with number of trips greater than 8. There are just 4 such observations\n",
        "df.drop(index=df[df.NumberOfTrips>10].index,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw1IaWvEj1B_"
      },
      "source": [
        "#### **Let's understand the distribution of the categorical variables**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntZRNokhgIkE"
      },
      "source": [
        "**Number of Person Visiting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSrPk04tkX0c"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x = df['NumberOfPersonVisiting'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4I2SdpAkjMv"
      },
      "outputs": [],
      "source": [
        "df['NumberOfPersonVisiting'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1-PsJ6jkX0c"
      },
      "source": [
        "- Most customers have 3 persons who are visiting with them. This can be because most people like to travel with family.\n",
        "- As mentioned earlier, there are just 3 observations where the number of persons visiting with the customers are 5 i.e. 0.1%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESYyvufTgIkF"
      },
      "source": [
        "**Occupation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRj88oPmkX0c"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x = df['Occupation'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZaKPI_Ek65O"
      },
      "outputs": [],
      "source": [
        "df['Occupation'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uNxEKw9kX0d"
      },
      "source": [
        "- The majority of customers i.e. 91% are either salaried or owns a small business. \n",
        "- As mentioned earlier, the freelancer category has only 2 observations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC3VR_T3gIkF"
      },
      "source": [
        "**City Tier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQ-AZSj7kX0d"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x = df['CityTier'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-oXvgZtlIyu"
      },
      "outputs": [],
      "source": [
        "df['CityTier'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVlbCAcokX0d"
      },
      "source": [
        "- Most of the customers i.e. approx 65% are from tier 1 cities. This can be because of better living standards and exposure as compared to tier 2 and tier 3 cities.\n",
        "- Surprisingly, tier 3 cities have a much higher count than tier 2 cities. This can be because the company has less marketing in tier 2 cities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIgry-x0gIkG"
      },
      "source": [
        "**Gender**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HM511RGXkX0d"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x = df['Gender'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uR4mLFTHlXFN"
      },
      "outputs": [],
      "source": [
        "df['Gender'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kNC16PSkX0d"
      },
      "source": [
        "- Male customers are more than the number of female customers\n",
        "- There are approx 60% male customers as compared to 40% female customers\n",
        "- This might be because males do the booking/inquiry when traveling with females which imply that males are the direct customers of the company."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84crWuHrgIkG"
      },
      "source": [
        "**Number of Follow ups**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7in9k2RGkX0d"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x = df['NumberOfFollowups'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtX70KdElkH-"
      },
      "outputs": [],
      "source": [
        "df['NumberOfFollowups'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Wy1s4RGkX0d"
      },
      "source": [
        "- We can see that company usually follow-ups with 3 or 4 times with their customers\n",
        "- We can explore this further and observe which number of follow-ups have more customers who buy the product."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFom9DPqgIkH"
      },
      "source": [
        "**Product Pitched**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUhik1pNkX0e"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x = df['ProductPitched'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYzG4Dvhl2JE"
      },
      "outputs": [],
      "source": [
        "df['ProductPitched'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQe9A0iKkX0e"
      },
      "source": [
        "- The company pitches Deluxe or Basic packages to their customers more than the other packages. \n",
        "- This might be because the company makes more profit from Deluxe or Basic packages or these packages are less expensive, so preferred by the majority of the customers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEVhfP09gIkI"
      },
      "source": [
        "**Type of Contact**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J57eCK0CkX0e"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x = df['TypeofContact'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8NZrtbmmFEm"
      },
      "outputs": [],
      "source": [
        "df['TypeofContact'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teBTDUXFkX0e"
      },
      "source": [
        "- There are approx 70% of customers who reached out to the company first i.e. self-inquiry. \n",
        "- This shows the positive outreach of the company as most of the inquires are initiated from the customer's end."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj-rDRnqgIkK"
      },
      "source": [
        "**Designation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rbIF60_kX0g"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x = df['Designation'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjlVLff9mYeH"
      },
      "outputs": [],
      "source": [
        "df['Designation'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6ePNIsZkX0g"
      },
      "source": [
        "- Approx 73% of the customers are at the executive or manager level.\n",
        "- We can see that the higher the position, the lesser number of observations which makes sense as executives/managers are more common than AVP/VP. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2zlzr2ygIkL"
      },
      "source": [
        "**Product Taken**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tcMexqYkX0g"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x = df['ProdTaken'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ma5lBQHXmj_u"
      },
      "outputs": [],
      "source": [
        "df['ProdTaken'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJz0-4ZWkX0g"
      },
      "source": [
        "- This plot shows the distribution of both classes in the target variable is `imbalanced`.\n",
        "- We only have approx 19% of customers who have purchased the product."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arranged-courtesy"
      },
      "source": [
        "### **Question 3: Bivariate Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4vIqPb9aaZW"
      },
      "source": [
        "#### **Question 3.1: Find and visualize the correlation matrix using a heatmap and write your observations from the plot. (2 Marks)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgoUpHy-j2Je"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "cols_list = data.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.heatmap(________________)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbYpvP7kozs_"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJhhg4y4i3wO"
      },
      "source": [
        "We will define a **stacked barplot()** function to help analyse how the target variable varies across predictor categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjDZRQMWiCEs"
      },
      "outputs": [],
      "source": [
        "# Defining the stacked_barplot() function\n",
        "def stacked_barplot(data,predictor,target,figsize=(10,6)):\n",
        "  (pd.crosstab(data[predictor],data[target],normalize='index')*100).plot(kind='bar',figsize=figsize,stacked=True)\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  plt.ylabel(target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75988GXzuEub"
      },
      "source": [
        "#### **Question 3.2: Plot the stacked barplot for the variable `Marital Status` against the target variable `ProdTaken` using the stacked_barplot  function provided and write your insights. (1 Mark)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUf03uGBj2ME"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "stacked_barplot(___________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgH_HM0YgIjx"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFzlIzGupXyv"
      },
      "source": [
        "#### **Question 3.3: Plot the stacked barplot for the variable `ProductPitched` against the target variable `ProdTaken` using the stacked_barplot  function provided and write your insights. (1 Mark)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhv7jubVpkNO"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "stacked_barplot(___________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUMOofPKpixu"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SLM1D8khiSM"
      },
      "source": [
        "**Let's plot the stacked barplot for the variable `Passport` against the target variable `ProdTaken` using the stacked_barplot function.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmF3Zfl9hiSM"
      },
      "outputs": [],
      "source": [
        "stacked_barplot(data, \"Passport\", \"ProdTaken\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GyUAraYDIH5"
      },
      "source": [
        "- The conversion rate for customers with a passport is higher as compared to the customers without a passport.\n",
        "- The company should customize more international packages to attract more such customers.\n",
        "\n",
        "\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0kpXi0LqJDv"
      },
      "source": [
        "**Let's plot the stacked barplot for the variable `Designation` against the target variable `ProdTaken` using the stacked_barplot function.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9YvbEWvhiSN"
      },
      "outputs": [],
      "source": [
        "stacked_barplot(data, \"Designation\", \"ProdTaken\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3r6cCM8hiSN"
      },
      "source": [
        "- The conversion rate of executives is higher than other designations.\n",
        "- Customers at VP and AVP positions have the least conversion rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfU4917Zq8U3"
      },
      "source": [
        "## **Data Preparation for Modeling**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auwCqZszDIH9"
      },
      "source": [
        "**Separating the independent variables (X) and the dependent variable (Y)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4swsr7sDIH9"
      },
      "outputs": [],
      "source": [
        "# Separating target variable and other variables\n",
        "X=data.drop(columns='ProdTaken')\n",
        "Y=data['ProdTaken']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tp8KkqheDIH9"
      },
      "source": [
        " **As we aim to predict customers who are more likely to buy the product, we should drop the columns `DurationOfPitch', 'NumberOfFollowups', 'ProductPitched', 'PitchSatisfactionScore'` as these columns would not be available at the time of prediction for new data.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fgMRSK1DIH9"
      },
      "outputs": [],
      "source": [
        "# Dropping columns\n",
        "X.drop(columns=['DurationOfPitch','NumberOfFollowups','ProductPitched','PitchSatisfactionScore'],inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEjv3vTBrF4w"
      },
      "source": [
        "**Splitting the data into a 70% train and 30% test set**\n",
        "\n",
        "Some classification problems can exhibit a large imbalance in the distribution of the target classes: for instance there could be several times more negative samples than positive samples. In such cases it is recommended to use the stratified sampling technique to ensure that relative class frequencies are approximately preserved in each train and validation fold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPka8FBBDIH-"
      },
      "outputs": [],
      "source": [
        "# Splitting the data into train and test sets\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.30,random_state=1,stratify=Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLameBYBDIH-"
      },
      "source": [
        "**As we saw earlier, our data has missing values. We will impute missing values using median for continuous variables and mode for categorical variables. We will use `SimpleImputer` to do this.**\n",
        "\n",
        "**The `SimpleImputer` provides basic strategies for imputing missing values. Missing values can be imputed with a provided constant value, or using the statistics (mean, median, or most frequent) of each column in which the missing values are located.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfK1DgcCDIH-"
      },
      "outputs": [],
      "source": [
        "si1=SimpleImputer(strategy='median')\n",
        "\n",
        "median_imputed_col=['Age','MonthlyIncome','NumberOfTrips']\n",
        "\n",
        "# Fit and transform the train data\n",
        "X_train[median_imputed_col]=si1.fit_transform(X_train[median_imputed_col])\n",
        "\n",
        "#Transform the test data i.e. replace missing values with the median calculated using training data\n",
        "X_test[median_imputed_col]=si1.transform(X_test[median_imputed_col])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BI2-b35WDIH-"
      },
      "outputs": [],
      "source": [
        "si2=SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "mode_imputed_col=['TypeofContact','PreferredPropertyStar','NumberOfChildrenVisiting']\n",
        "\n",
        "# Fit and transform the train data\n",
        "X_train[mode_imputed_col]=si2.fit_transform(X_train[mode_imputed_col])\n",
        "\n",
        "# Transform the test data i.e. replace missing values with the mode calculated using training data\n",
        "X_test[mode_imputed_col]=si2.transform(X_test[mode_imputed_col])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKM7o76_DIH-"
      },
      "outputs": [],
      "source": [
        "# Checking that no column has missing values in train or test sets\n",
        "print(X_train.isna().sum())\n",
        "print('-'*30)\n",
        "print(X_test.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3P8LcypmhiSO"
      },
      "source": [
        "**Let's create dummy variables for string type variables and convert other column types back to float.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xMXqe8BhiSP"
      },
      "outputs": [],
      "source": [
        "#converting data types of columns to float\n",
        "for column in ['NumberOfPersonVisiting', 'Passport', 'OwnCar']:\n",
        "    X_train[column]=X_train[column].astype('float')\n",
        "    X_test[column]=X_test[column].astype('float')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6pNd-OrhiSP"
      },
      "outputs": [],
      "source": [
        "#List of columns to create a dummy variables\n",
        "col_dummy=['TypeofContact', 'Occupation', 'Gender', 'MaritalStatus', 'Designation', 'CityTier']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4TFjBVfDIH_"
      },
      "outputs": [],
      "source": [
        "#Encoding categorical varaibles\n",
        "X_train=pd.get_dummies(X_train, columns=col_dummy, drop_first=True)\n",
        "X_test=pd.get_dummies(X_test, columns=col_dummy, drop_first=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXukgbNkDIH_"
      },
      "source": [
        "## **Model evaluation criterion:**\n",
        "\n",
        "#### **The model can make wrong predictions as:**\n",
        "1. Predicting a customer will buy the product and the customer doesn't buy - Loss of resources\n",
        "2. Predicting a customer will not buy the product and the customer buys - Loss of opportunity\n",
        "\n",
        "#### **Which case is more important?** \n",
        "* Predicting that customer will not buy the product but he buys i.e. losing on a potential source of income for the company because that customer will not be targeted by the marketing team when he should be targeted.\n",
        "\n",
        "#### **How to reduce this loss i.e need to reduce False Negatives?**\n",
        "* The company wants Recall to be maximized, the greater the Recall lesser the chances of false negatives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqJc4i43DIH_"
      },
      "source": [
        "### **Building the model**\n",
        "\n",
        "We will be building 4 different models:\n",
        "\n",
        "- **Logistic Regression**\n",
        "- **Support Vector Machine(SVM)**\n",
        "- **Decision Tree**\n",
        "- **Random Forest**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-VRlSYYcrl-"
      },
      "source": [
        "**Also, let's create a function to calculate and print the classification report and confusion matrix so that we don't have to rewrite the same code repeatedly for each model.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asqUXWEl9bss"
      },
      "outputs": [],
      "source": [
        "# Creating metric function \n",
        "def metrics_score(actual, predicted):\n",
        "    print(classification_report(actual, predicted))\n",
        "\n",
        "    cm = confusion_matrix(actual, predicted)\n",
        "    plt.figure(figsize=(8,5))\n",
        "    \n",
        "    sns.heatmap(cm, annot=True,  fmt='.2f')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYxShb2N8fEO"
      },
      "source": [
        "### **Question 4: Logistic Regression (6 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsA_ClRLciDy"
      },
      "source": [
        "#### **Question 4.1: Build a Logistic Regression model (Use the sklearn library) (1 Mark)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suMljThs8enN"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "# Fitting logistic regression model\n",
        "lg = ___________\n",
        "lg.fit(__________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yimvLBJXc11N"
      },
      "source": [
        "#### **Question 4.2: Check the performance of the model on train and test data (2 Marks)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7x7wqtx8jz2"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "# Checking the performance on the training data\n",
        "y_pred_train = lg.____________\n",
        "metrics_score(___________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVd2uppKdDCL"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQXto1sQHVQJ"
      },
      "source": [
        "#### Let's check the performance on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVMvhHxUHVpQ"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "# Checking the performance on the test dataset\n",
        "y_pred_test = lg._________\n",
        "metrics_score(________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC28gYUYzwEv"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdNuEOU80Zkw"
      },
      "source": [
        "\n",
        "#### **Question 4.3: Find the optimal threshold for the model using the Precision-Recall Curve. (1 Mark)**\n",
        "\n",
        "Precision-Recall curve summarizes the trade-off between the true positive rate and the positive predictive value for a predictive model using different probability thresholds.\n",
        "\n",
        "Let's use the Precision-Recall curve and see if we can find a **better threshold.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXbUL7c8HY8K"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "# Predict_proba gives the probability of each observation belonging to each class\n",
        "y_scores_lg=lg.predict_proba(_______)\n",
        "\n",
        "precisions_lg, recalls_lg, thresholds_lg = precision_recall_curve(____________)\n",
        "\n",
        "# Plot values of precisions, recalls, and thresholds\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(thresholds_lg, precisions_lg[:-1], 'b--', label='precision')\n",
        "plt.plot(thresholds_lg, recalls_lg[:-1], 'g--', label = 'recall')\n",
        "plt.xlabel('Threshold')\n",
        "plt.legend(loc='upper left')\n",
        "plt.ylim([0,1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BksJ4-I0gKP"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbcJKtwUHsgw"
      },
      "outputs": [],
      "source": [
        "# Setting the optimal threshold\n",
        "optimal_threshold = ___________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpgzPdCUI_Ef"
      },
      "source": [
        "#### **Question 4.4: Check the performance of the model on train and test data using the optimal threshold. (2 Marks)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHOUY7OEI8gR"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "# Creating confusion matrix\n",
        "y_pred_train = lg.predict_proba(________)\n",
        "metrics_score(______________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjYpcggx0wU9"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EmVf96xJI37"
      },
      "source": [
        "#### Let's check the performance on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3zQ4LbVJCrd"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "y_pred_test = lg.predict_proba(__________)\n",
        "metrics_score(____________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oze9cJcd0-gR"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkuW9FVLJVQ2"
      },
      "source": [
        "### **Question 5: Support Vector Machines (11 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiGvu2xkLXsD"
      },
      "source": [
        "To accelerate SVM training, let's scale the data for support vector machines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aMGEUTBLTTv"
      },
      "outputs": [],
      "source": [
        "scaling = MinMaxScaler(feature_range=(-1,1)).fit(X_train)\n",
        "X_train_scaled = scaling.transform(X_train)\n",
        "X_test_scaled = scaling.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpZZ0BKMJZ8T"
      },
      "source": [
        "Let's build the models using the two of the widely used kernel functions:\n",
        "\n",
        "1.   **Linear Kernel**\n",
        "2.   **RBF Kernel**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spCEVB4QaWP1"
      },
      "source": [
        "#### **Question 5.1: Build a Support Vector Machine model using a linear kernel (1 Mark)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geML3KVPJPSV"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "svm = SVC(kernel=______,probability=True) # Linear kernal or linear decision boundary\n",
        "model = svm.fit(___________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emGgjsDIKwzF"
      },
      "source": [
        "#### **Question 5.2: Check the performance of the model on train and test data (2 Marks)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuQQ4TegKM-P"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "y_pred_train_svm = model.predict(__________)\n",
        "metrics_score(______________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv7CpiYp6GTK"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNLaYhyuK-mL"
      },
      "source": [
        "#### Checking model performance on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhcVkJq6KzHM"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "y_pred_test_svm = model.predict(___________)\n",
        "metrics_score(____________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3HqDU-uahrx"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pAjYUYobolP"
      },
      "source": [
        "#### **Question 5.3: Find the optimal threshold for the model using the Precision-Recall Curve. (1 Mark)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IU2if8VLCjD"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "# Predict on train data\n",
        "y_scores_svm=model.predict_proba(____________)\n",
        "\n",
        "precisions_svm, recalls_svm, thresholds_svm = _________________\n",
        "\n",
        "# Plot values of precisions, recalls, and thresholds\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(thresholds_svm, precisions_svm[:-1], 'b--', label='precision')\n",
        "plt.plot(thresholds_svm, recalls_svm[:-1], 'g--', label = 'recall')\n",
        "plt.xlabel('Threshold')\n",
        "plt.legend(loc='upper left')\n",
        "plt.ylim([0,1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO9-qjzZEVmt"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yckyrISfLNH-"
      },
      "outputs": [],
      "source": [
        "optimal_threshold_svm=____________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiunZMLyb0ct"
      },
      "source": [
        "#### **Question 5.4: Check the performance of the model on train and test data using the optimal threshold. (2 Marks)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2B-1fHQcDPM"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "y_pred_train_svm = model.________________\n",
        "metrics_score(__________________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcBu0A7H7Q2h"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFnTuaL6LRLm"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "y_pred_test = model._______________\n",
        "metrics_score(________________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp93x26e7WG1"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKlXkuXvLfTy"
      },
      "source": [
        "#### **Question 5.5: Build a Support Vector Machines model using an RBF kernel (1 Mark)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAycHBYhLZmy"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "svm_rbf=SVC(kernel=_______,probability=True)\n",
        "svm_rbf.fit(______________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieQhJrp-LlhI"
      },
      "source": [
        "#### **Question 5.6: Check the performance of the model on train and test data (2 Marks)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9kbNV5kLilg"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "y_pred_train_svm = svm_rbf.predict(______________)\n",
        "metrics_score(_______________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt4rM9Qn-pMM"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBDfwhE3L5vq"
      },
      "source": [
        "#### Checking model performance on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oq6wErPMLp00"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "y_pred_test = svm_rbf.predict(________________)\n",
        "\n",
        "metrics_score(_____________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x4oQS2R-0pv"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBBhKkqmSVEc"
      },
      "outputs": [],
      "source": [
        "# Predict on train data\n",
        "y_scores_svm=svm_rbf.predict_proba(X_train_scaled)\n",
        "\n",
        "precisions_svm, recalls_svm, thresholds_svm = precision_recall_curve(y_train, y_scores_svm[:,1])\n",
        "\n",
        "# Plot values of precisions, recalls, and thresholds\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(thresholds_svm, precisions_svm[:-1], 'b--', label='precision')\n",
        "plt.plot(thresholds_svm, recalls_svm[:-1], 'g--', label = 'recall')\n",
        "plt.xlabel('Threshold')\n",
        "plt.legend(loc='upper left')\n",
        "plt.ylim([0,1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z5EtdTyTvCP"
      },
      "outputs": [],
      "source": [
        "optimal_threshold_svm=__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIaBeRB6-oao"
      },
      "source": [
        "#### **Question 5.7: Check the performance of the model on train and test data using the optimal threshold. (2 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaLTL76V3hNr"
      },
      "source": [
        "#### Checking model performance on training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zJb5zS1Tvc5"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "y_pred_train_svm = model.predict_proba(_____________)\n",
        "metrics_score(____________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgGgGFiB4Fy4"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3b19SQ_3va_"
      },
      "source": [
        "#### Checking model performance on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGVljAerTzry"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "y_pred_test = svm_rbf.predict_proba(____________)\n",
        "metrics_score(____________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDk_-sA2_SR7"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "separated-prague"
      },
      "source": [
        "### **Question 6: Decision Trees (7 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "immune-malta"
      },
      "source": [
        "#### **Question 6.1: Build a Decision Tree Model (1 Mark)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "recognized-nurse"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "model_dt = ______________\n",
        "model_dt.fit(______________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "identified-upper"
      },
      "source": [
        "#### **Question 6.2: Check the performance of the model on train and test data (2 Marks)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "female-kennedy"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "# Checking performance on the training dataset\n",
        "pred_train_dt = model_dt.predict(_____________)\n",
        "metrics_score(_________________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laden-london"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neither-omaha"
      },
      "source": [
        "#### Checking model performance on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42537a82"
      },
      "outputs": [],
      "source": [
        "pred_test_dt = model_dt.predict(____________)\n",
        "metrics_score(____________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "previous-stamp"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "detailed-possible"
      },
      "source": [
        " #### **Question 6.3: Perform hyperparameter tuning for the decision tree model using GridSearch CV (1 Mark)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "romantic-stationery"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "# Choose the type of classifier.\n",
        "estimator = ________________\n",
        "\n",
        "# Grid of parameters to choose from\n",
        "parameters = {\n",
        "    \"max_depth\": np.arange(2, 7, 2),\n",
        "    \"max_leaf_nodes\": [50, 75, 150, 250],\n",
        "    \"min_samples_split\": [10, 30, 50, 70],\n",
        "}\n",
        "\n",
        "\n",
        "# Run the grid search\n",
        "grid_obj = GridSearchCV(_____________)\n",
        "grid_obj = grid_obj.fit(______________)\n",
        "\n",
        "# Set the clf to the best combination of parameters\n",
        "estimator = grid_obj.best_estimator_\n",
        "\n",
        "# Fit the best algorithm to the data.\n",
        "estimator.fit(______________-)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "concrete-season"
      },
      "source": [
        "#### **Question 6.4: Check the performance of the model on the train and test data using the tuned model (2 Mark)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "endangered-image"
      },
      "source": [
        "#### Checking performance on the training set "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skilled-poster"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "# Checking performance on the training dataset\n",
        "dt_tuned = estimator.predict(__________)\n",
        "metrics_score(________________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paWakCn1HzFT"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "killing-magnet"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "# Checking performance on the training dataset\n",
        "y_pred_tuned = estimator.predict(________)\n",
        "metrics_score(_____________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "growing-excitement"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frequent-grenada"
      },
      "source": [
        "#### **Visualizing the Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "driving-state"
      },
      "outputs": [],
      "source": [
        "feature_names = list(X_train.columns)\n",
        "plt.figure(figsize=(20, 10))\n",
        "out = tree.plot_tree(\n",
        "    estimator,\n",
        "    max_depth=4,\n",
        "    feature_names=feature_names,\n",
        "    filled=True,\n",
        "    fontsize=9,\n",
        "    node_ids=False,\n",
        "    class_names=None,\n",
        ")\n",
        "# below code will add arrows to the decision tree split if they are missing\n",
        "for o in out:\n",
        "    arrow = o.arrow_patch\n",
        "    if arrow is not None:\n",
        "        arrow.set_edgecolor(\"black\")\n",
        "        arrow.set_linewidth(1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rational-details"
      },
      "source": [
        "#### **Question 6.5: What are some important features based on the tuned decision tree? (1 Mark)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "secure-killing"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "# Importance of features in the tree building\n",
        "\n",
        "importances = estimator.___________\n",
        "indices = np.argsort(____________)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(\"Feature Importances\")\n",
        "plt.barh(range(len(indices)), importances[indices], color=\"violet\", align=\"center\")\n",
        "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "plt.xlabel(\"Relative Importance\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "differential-perth"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tkjO8cKHMO5"
      },
      "source": [
        "### **Question 7: Random Forest (4 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FuGyOqjc_4b"
      },
      "source": [
        "#### **Question 7.1: Build a Random Forest Model (1 Mark)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIsbmNYal1rj"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "rf_estimator = ______________\n",
        "\n",
        "rf_estimator.fit(___________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxYjZqTjd-Qk"
      },
      "source": [
        "#### **Question 7.2: Check the performance of the model on the train and test data (2 Marks)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6jrat9ko0LO"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "y_pred_train_rf = rf_estimator.predict(___________)\n",
        "\n",
        "metrics_score(______________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0AYl0ZDIWkP"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vMZodtJ1k4z"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "y_pred_test_rf = rf_estimator.predict(______________)\n",
        "\n",
        "metrics_score(______________)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8hPHFpRRTCr"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLrG8f7YeG9b"
      },
      "source": [
        "#### **Question 7.3: What are some important features based on the Random Forest? (1 Mark)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rAIPf5BSKes"
      },
      "source": [
        "Let's check the feature importance of the Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lknDAkbZSI6B"
      },
      "outputs": [],
      "source": [
        "# Remove _________ and complete the code\n",
        "\n",
        "importances = rf_estimator._________________\n",
        "\n",
        "columns = X.columns\n",
        "\n",
        "importance_df = pd.DataFrame(____________________)\n",
        "\n",
        "plt.figure(figsize = (13, 13))\n",
        "\n",
        "sns.barplot(x = importance_df.Importance, y = importance_df.index, color=\"violet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuL7_Wc5Swa1"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpgnsxDNAHXE"
      },
      "source": [
        "### **Question 8: Conclude ANY FOUR key takeaways for business recommendations (4 Marks)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsVQ72VQDIIQ"
      },
      "source": [
        "**Write your answers here:_____**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt4hOsXB_PTv"
      },
      "source": [
        "## **Happy Learning!**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}